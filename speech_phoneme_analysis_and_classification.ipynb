{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action = \"ignore\", category = SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting feature list from csv file\n",
    "features = pd.read_csv(r'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating matrix of just formant data\n",
    "data_matrix = features.iloc[:, -3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      2\n",
      "2      3\n",
      "3      1\n",
      "4      2\n",
      "      ..\n",
      "145    2\n",
      "146    3\n",
      "147    1\n",
      "148    2\n",
      "149    3\n",
      "Name: class_number, Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dataframe with just class number for each row\n",
    "data_labels = features.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kList = [1, 3, 5, 7, 10] # k values that will be tried\n",
    "distMetricList = [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]\n",
    "n = 1000 # number of repetitions\n",
    "\n",
    "# labels for graphs\n",
    "phoneme_labels = [\"IY\", \"AE\", \"ER\"]\n",
    "for distMetric in distMetricList:\n",
    "    for k in kList:\n",
    "        # initialising all values in confusion array to 0\n",
    "        confusionArray = [[0] * 3 for _ in range(3)]\n",
    "        \n",
    "        for i in range(n):    \n",
    "            # splitting the training and test data with a 3:1 split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data_matrix, data_labels, test_size = 0.25)\n",
    "\n",
    "            # training the model\n",
    "            knn_model = KNeighborsClassifier(n_neighbors = k, metric = distMetric)\n",
    "            knn_model.fit(X_train, y_train)\n",
    "\n",
    "            # getting list of predicited results\n",
    "            test_preds = knn_model.predict(X_test)\n",
    "\n",
    "            # joining list of predicted results to test set\n",
    "            X_test['predicted'] = test_preds.tolist()\n",
    "\n",
    "            # looping through test set and adding to confusion array depending of predicted and actual result\n",
    "            for i, row in X_test.iterrows():\n",
    "                if X_test.loc[i]['predicted'] == 1 and features.iloc[i]['class_number'] == 1:\n",
    "                    confusionArray[0][0] += 1\n",
    "                elif X_test.loc[i]['predicted'] == 1 and features.iloc[i]['class_number'] == 2:\n",
    "                    confusionArray[0][1] += 1\n",
    "                elif X_test.loc[i]['predicted'] == 1 and features.iloc[i]['class_number'] == 3:\n",
    "                    confusionArray[0][2] += 1\n",
    "                elif X_test.loc[i]['predicted'] == 2 and features.iloc[i]['class_number'] == 1:\n",
    "                    confusionArray[1][0] += 1\n",
    "                elif X_test.loc[i]['predicted'] == 2 and features.iloc[i]['class_number'] == 2:\n",
    "                    confusionArray[1][1] += 1\n",
    "                elif X_test.loc[i]['predicted'] == 2 and features.iloc[i]['class_number'] == 3:\n",
    "                    confusionArray[1][2] += 1\n",
    "                elif X_test.loc[i]['predicted'] == 3 and features.iloc[i]['class_number'] == 1:\n",
    "                    confusionArray[2][0] += 1\n",
    "                elif X_test.loc[i]['predicted'] == 3 and features.iloc[i]['class_number'] == 2:\n",
    "                    confusionArray[2][1] += 1\n",
    "                elif X_test.loc[i]['predicted'] == 3 and features.iloc[i]['class_number'] == 3:\n",
    "                    confusionArray[2][2] += 1\n",
    "\n",
    "        # getting average of each k value before plotting graph\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                confusionArray[i][j] /= n\n",
    "\n",
    "        dataFrameGraph = pd.DataFrame(confusionArray, index = [i for i in phoneme_labels], \n",
    "                                      columns = [i for i in phoneme_labels])\n",
    "        plt.figure(figsize = (4, 4))\n",
    "        plt.xlabel(\"Actual Phoneme\")\n",
    "        plt.ylabel(\"Predicted Phoneme\")\n",
    "        plt.title(\"Confusion Array for k = \" + str(k) + \"\\nwith distance metric: \" + distMetric)\n",
    "        sn.heatmap(dataFrameGraph, annot = True)\n",
    "        # saving all graphs as images\n",
    "#         plt.savefig(\"k_\" + str(k) + \"-dist_\" + distMetric + \".png\", transparent = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
